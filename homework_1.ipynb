{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading all information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException, StaleElementReferenceException\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preferences\n",
    "\n",
    "def ffx_preferences(dfolder, download=False, firefox_binary_path=None):\n",
    "    \"\"\"\n",
    "    Sets the preferences of the Firefox browser: download path.\n",
    "    \"\"\"\n",
    "    options = Options()\n",
    "\n",
    "    # Set the Firefox binary location if provided\n",
    "    if firefox_binary_path:\n",
    "        options.binary_location = firefox_binary_path  \n",
    "\n",
    "    # Set download folder preferences\n",
    "    options.set_preference(\"browser.download.dir\", dfolder)  # Predefine download folder\n",
    "    options.set_preference(\"browser.download.folderList\", 2)  # Use custom download folder\n",
    "    options.set_preference(\"browser.download.manager.showWhenStarting\", False)  # Disable popups\n",
    "    options.set_preference(\"browser.helperApps.neverAsk.saveToDisk\",\n",
    "                           \"application/msword,application/rtf,application/csv,text/csv,image/png,image/jpeg,application/pdf,text/html,text/plain,application/octet-stream\")\n",
    "\n",
    "    # Enable automatic PDF downloads\n",
    "    if download:\n",
    "        options.set_preference(\"browser.helperApps.neverAsk.saveToDisk\", \"application/pdf,application/x-pdf\")\n",
    "        options.set_preference(\"pdfjs.disabled\", True)  # Disable built-in PDF viewer\n",
    "\n",
    "    return options\n",
    "\n",
    "def start_up(link, dfolder, geko_path, firefox_binary_path=None, download=True):\n",
    "    \"\"\"\n",
    "    Initializes the Firefox browser with the given settings.\n",
    "    \"\"\"\n",
    "    os.makedirs(dfolder, exist_ok=True)  # Ensure download directory exists\n",
    "\n",
    "    options = ffx_preferences(dfolder, download, firefox_binary_path)\n",
    "\n",
    "    service = Service(executable_path=geko_path)\n",
    "    browser = webdriver.Firefox(service=service, options=options)\n",
    "    \n",
    "    # Open the target link\n",
    "    browser.get(link)\n",
    "    time.sleep(5)  # Adjust as needed\n",
    "    return browser\n",
    "\n",
    "def check_and_click(browser, xpath, type, timeout=10):\n",
    "    '''\n",
    "    This function returns:\n",
    "    - True if click was successful.\n",
    "    - False otherwise.\n",
    "    '''\n",
    "    try:\n",
    "        wait = WebDriverWait(browser, timeout)\n",
    "        \n",
    "        if type.lower() == \"xpath\":\n",
    "            element = wait.until(EC.element_to_be_clickable((By.XPATH, xpath)))\n",
    "        elif type.lower() == \"id\":\n",
    "            element = wait.until(EC.element_to_be_clickable((By.ID, xpath)))\n",
    "        elif type.lower() == \"css\":\n",
    "            element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, xpath)))\n",
    "        elif type.lower() == \"class\":\n",
    "            element = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, xpath)))\n",
    "        elif type.lower() == \"link\":\n",
    "            element = wait.until(EC.element_to_be_clickable((By.LINK_TEXT, xpath)))\n",
    "        else:\n",
    "            print(f\"Unsupported locator type: {type}\")\n",
    "            return False\n",
    "        \n",
    "        element.click()\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    except (ElementClickInterceptedException, NoSuchElementException, StaleElementReferenceException) as e:\n",
    "        print(f\"Error clicking element: {e}\")\n",
    "        return False\n",
    "    except TimeoutException:\n",
    "        print(f\"Timeout: Element not clickable after {timeout} seconds: {xpath}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected exception: {e}\")\n",
    "        return False\n",
    "    \n",
    "def check_obscures(browser, xpath, type):\n",
    "    \"\"\"\n",
    "    Checks if an element is being obstructed and clicks it if possible.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if type == \"xpath\":\n",
    "            browser.find_element('xpath', xpath).click()\n",
    "        elif type == \"id\":\n",
    "            browser.find_element('id', xpath).click()\n",
    "        elif type == \"css\":\n",
    "            browser.find_element('css selector', xpath).click()\n",
    "        elif type == \"class\":\n",
    "            browser.find_element('class name', xpath).click()\n",
    "        elif type == \"link\":\n",
    "            browser.find_element('link text', xpath).click()\n",
    "    except (ElementClickInterceptedException, NoSuchElementException, StaleElementReferenceException) as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening booking:\n",
    "firefox_binary_path = r\"C:\\Program Files\\Mozilla Firefox\\firefox.exe\"\n",
    "dfolder='./downloads'\n",
    "geko_path = r\"C:\\Users\\aleja\\OneDrive\\Escritorio\\Term_2\\Text_Mining\\geckodriver.exe\"\n",
    "link='https://www.booking.com/index.es.html'\n",
    "browser=start_up(link, dfolder, geko_path, firefox_binary_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated language selection\n",
    "\n",
    "# Language selection\n",
    "browser.find_element(By.XPATH, '//button[@aria-controls=\"header_language_picker\"]').click()\n",
    "# Selecting Spanish\n",
    "browser.find_element(By.XPATH, '//span[@lang=\"es\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cookie rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cookie consent rejected.\n"
     ]
    }
   ],
   "source": [
    "success = check_and_click(browser, \"onetrust-reject-all-handler\", \"id\", timeout=10)\n",
    "\n",
    "if success:\n",
    "    print(\"Cookie consent rejected.\")\n",
    "else:\n",
    "    print(\"Failed to reject cookies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding \"where are you going?\" Button\n",
    "time.sleep(3)  # Wait for 3 seconds before clicking\n",
    "browser.find_element(by=By.XPATH,value='//*[@id=\":rh:\"]').click()\n",
    "\n",
    "# Place input\n",
    "place = 'Barcelona' #switch to Lisboa (spanish for Lisbon)\n",
    "search1 = browser.find_element(by='xpath',value='//*[@id=\":rh:\"]')\n",
    "search1.send_keys(place)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicked the dates box.\n"
     ]
    }
   ],
   "source": [
    "# Clicking the date box\n",
    "\n",
    "locator = '[data-testid=\"searchbox-dates-container\"]'\n",
    "type = \"css\"\n",
    "success = check_and_click(browser, locator, type, timeout=10)\n",
    "if success:\n",
    "    print(\"Clicked the dates box.\")\n",
    "else:\n",
    "    print(\"Failed to click the dates box.\")\n",
    "\n",
    "# Selecting may according to the current month when the code is run\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current month number (1 = January, 2 = February, ..., 12 = December)\n",
    "current_month = datetime.now().month\n",
    "\n",
    "# Calculate the number of clicks needed to reach May (month 5)\n",
    "clicks_needed = max(0, 5 - current_month)\n",
    "\n",
    "# Click the \"Next month\" button the required number of times\n",
    "for _ in range(clicks_needed):\n",
    "    check_and_click(browser, '//button[@class=\"a83ed08757 c21c56c305 f38b6daa18 d691166b09 f671049264 f4552b6561 dc72a8413c f073249358\"]', \"xpath\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecting the dates\n",
    "path='//div[@id=\"calendar-searchboxdatepicker\"]//table[@class=\"eb03f3f27f\"]//tbody//td[@class=\"b80d5adb18\"]//span[@class=\"cf06f772fa ef091eb985\"]'\n",
    "dates = browser.find_elements('xpath',path)\n",
    "\n",
    "arrival = '29-05-2025' #input day of arrival as day , month\n",
    "departure = '02-06-2025' # input day of departure as day, month\n",
    "\n",
    "\n",
    "for date in dates:\n",
    "    if date.get_attribute(\"data-date\") == f\"2025-{arrival.split('-')[1]}-{arrival.split('-')[0]}\":\n",
    "        date.click()\n",
    "    if date.get_attribute(\"data-date\") == f\"2025-{departure.split('-')[1]}-{departure.split('-')[0]}\":\n",
    "        date.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_element(by=By.XPATH,value='//button[@class=\"a83ed08757 c21c56c305 a4c1805887 f671049264 a2abacf76b c082d89982 cceeb8986b b9fd3c6b3c\"]').click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop-up closed.\n"
     ]
    }
   ],
   "source": [
    "# Closing Genius Pop Up (if it appears)\n",
    "try:\n",
    "    success = check_and_click(browser, '//div[@class=\"eb33ef7c47\"]//button[@class=\"a83ed08757 c21c56c305 f38b6daa18 d691166b09 ab98298258 f4552b6561\"]', \"xpath\")\n",
    "    if success:\n",
    "        print(\"Pop-up closed.\")\n",
    "except NoSuchElementException:\n",
    "    print(\"Pop-up did not appear, continuing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout: Element not clickable after 10 seconds: //button[@class=\"a83ed08757 c21c56c305 bf0537ecb5 f671049264 af7297d90d c0e0affd09\"]\n",
      "The 'Load More' button has been clicked 37 times\n"
     ]
    }
   ],
   "source": [
    "# Loading all results\n",
    "\n",
    "clicks = 0\n",
    "# Scrolling based on the height of the page.\n",
    "while True:\n",
    "    try:\n",
    "        total_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        scroll_position = (total_height * 10) - 200 \n",
    "        #we scroll to the bottom of the page, and then back up a bit to reach the desired button\n",
    "        browser.execute_script(f\"window.scrollTo(0, {scroll_position});\")\n",
    "\n",
    "        # Attempt to click the \"Load More\" button using check_and_click.\n",
    "        success = check_and_click(browser, '//button[@class=\"a83ed08757 c21c56c305 bf0537ecb5 f671049264 af7297d90d c0e0affd09\"]', \"xpath\", timeout=10)\n",
    "        \n",
    "        if not success:\n",
    "            break  # Exit loop if button is not found or not clickable.\n",
    "        \n",
    "        clicks += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error while scrolling and clicking: {e}\")\n",
    "        break\n",
    "\n",
    "print(f\"The 'Load More' button has been clicked {clicks} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_source = browser.page_source\n",
    "soup = BeautifulSoup(page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_hotels_metadata(soup):\n",
    "\n",
    "    #we will store each hotel metadata here   \n",
    "    hotel_metadadata = []\n",
    "\n",
    "    #this is our way to find all hotels from the soup\n",
    "    hotels = soup.find_all('div', {'data-testid': 'property-card'})\n",
    "    \n",
    "    for hotel in hotels:\n",
    "        # Extract hotel name\n",
    "        name = hotel.find('div', {'data-testid': 'title'}).get_text(strip=True) if hotel.find('div', {'data-testid': 'title'}) else \"NA\"\n",
    "        \n",
    "        # Extract price\n",
    "        price_unprocessed = hotel.find('span', {'class': 'f6431b446c fbfd7c1165 e84eb96b1f'}).get_text(strip=True) if hotel.find('span', {'class': 'f6431b446c fbfd7c1165 e84eb96b1f'}) else \"NA\"\n",
    "        price = re.sub(r'\\D', '', price_unprocessed)\n",
    "        \n",
    "        # Extract rating\n",
    "        rating_box = hotel.find('div', {'data-testid': 'review-score'})\n",
    "        rating = rating_box.find('div').get_text(strip=True)[-3:].replace(',', '.') if rating_box else \"NA\"\n",
    "\n",
    "        # Extract link to detailed hotel page\n",
    "        hotel_link = hotel.find('a', {'data-testid': 'title-link'})['href'] if hotel.find('a', {'data-testid': 'title-link'}) else None \n",
    "                \n",
    "        hotel_metadadata.append([name, price, rating, hotel_link])\n",
    "        df = pd.DataFrame(hotel_metadadata, columns=['Name', 'Price', 'Rating', 'Hotel Link'])\n",
    "    return df\n",
    "\n",
    "def scrape_hotel_description(detail_url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(detail_url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        description = soup.find('p', {'data-testid': 'property-description'}).get_text(strip=True) if soup.find('p', {'data-testid': 'property-description'}) else \"NA\"\n",
    "        return description\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping details from {detail_url}: {e}\")\n",
    "        return \"Error\"\n",
    "    \n",
    "def full_program(soup):\n",
    "    #Scrape the listing page using Selenium\n",
    "    metadata = scrape_hotels_metadata(soup)    \n",
    "    \n",
    "    #Scrape each hotel's detailed page for additional information\n",
    "    descriptions = []\n",
    "    for index, row in metadata.iterrows():\n",
    "        detail_url = row['Hotel Link']\n",
    "        if detail_url:\n",
    "            description = scrape_hotel_description(detail_url)\n",
    "            descriptions.append(description)\n",
    "            time.sleep(2)  # Add delay to avoid getting blocked\n",
    "        else:\n",
    "            descriptions.append(\"NA\")\n",
    "\n",
    "    # Add the descriptions to the DataFrame\n",
    "    metadata['Description'] = descriptions\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    metadata.to_csv(\"hotel_data.csv\", index=False)\n",
    "    print(\"Hotel data saved to hotel_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[158], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mfull_program\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoup\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[157], line 51\u001b[0m, in \u001b[0;36mfull_program\u001b[1;34m(soup)\u001b[0m\n\u001b[0;32m     49\u001b[0m detail_url \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHotel Link\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detail_url:\n\u001b[1;32m---> 51\u001b[0m     description \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_hotel_description\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetail_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     descriptions\u001b[38;5;241m.\u001b[39mappend(description)\n\u001b[0;32m     53\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Add delay to avoid getting blocked\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[157], line 33\u001b[0m, in \u001b[0;36mscrape_hotel_description\u001b[1;34m(detail_url)\u001b[0m\n\u001b[0;32m     29\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     31\u001b[0m }\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetail_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m     description \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata-testid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperty-description\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata-testid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperty-description\u001b[39m\u001b[38;5;124m'\u001b[39m}) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNA\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\site-packages\\requests\\sessions.py:746\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 746\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\site-packages\\requests\\models.py:902\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 902\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\site-packages\\urllib3\\response.py:1057\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m-> 1057\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\site-packages\\urllib3\\response.py:1206\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1203\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1206\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1208\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\site-packages\\urllib3\\response.py:1125\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1125\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1126\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\socket.py:716\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 716\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\envs\\myenv\\lib\\ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = full_program(soup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
