{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading all information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException, StaleElementReferenceException\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preferences\n",
    "\n",
    "def ffx_preferences(dfolder, download=False, firefox_binary_path=None):\n",
    "    \"\"\"\n",
    "    Sets the preferences of the Firefox browser: download path.\n",
    "    \"\"\"\n",
    "    options = Options()\n",
    "\n",
    "    # Set the Firefox binary location if provided\n",
    "    if firefox_binary_path:\n",
    "        options.binary_location = firefox_binary_path  \n",
    "\n",
    "    # Set download folder preferences\n",
    "    options.set_preference(\"browser.download.dir\", dfolder)  # Predefine download folder\n",
    "    options.set_preference(\"browser.download.folderList\", 2)  # Use custom download folder\n",
    "    options.set_preference(\"browser.download.manager.showWhenStarting\", False)  # Disable popups\n",
    "    options.set_preference(\"browser.helperApps.neverAsk.saveToDisk\",\n",
    "                           \"application/msword,application/rtf,application/csv,text/csv,image/png,image/jpeg,application/pdf,text/html,text/plain,application/octet-stream\")\n",
    "\n",
    "    # Enable automatic PDF downloads\n",
    "    if download:\n",
    "        options.set_preference(\"browser.helperApps.neverAsk.saveToDisk\", \"application/pdf,application/x-pdf\")\n",
    "        options.set_preference(\"pdfjs.disabled\", True)  # Disable built-in PDF viewer\n",
    "\n",
    "    return options\n",
    "\n",
    "def start_up(link, dfolder, geko_path, firefox_binary_path=None, download=True):\n",
    "    \"\"\"\n",
    "    Initializes the Firefox browser with the given settings.\n",
    "    \"\"\"\n",
    "    os.makedirs(dfolder, exist_ok=True)  # Ensure download directory exists\n",
    "\n",
    "    options = ffx_preferences(dfolder, download, firefox_binary_path)\n",
    "\n",
    "    service = Service(executable_path=geko_path)\n",
    "    browser = webdriver.Firefox(service=service, options=options)\n",
    "    \n",
    "    # Open the target link\n",
    "    browser.get(link)\n",
    "    time.sleep(5)  # Adjust as needed\n",
    "    return browser\n",
    "\n",
    "def check_and_click(browser, xpath, type, timeout=10):\n",
    "    '''\n",
    "    This function returns:\n",
    "    - True if click was successful.\n",
    "    - False otherwise.\n",
    "    '''\n",
    "    try:\n",
    "        wait = WebDriverWait(browser, timeout)\n",
    "        \n",
    "        if type.lower() == \"xpath\":\n",
    "            element = wait.until(EC.element_to_be_clickable((By.XPATH, xpath)))\n",
    "        elif type.lower() == \"id\":\n",
    "            element = wait.until(EC.element_to_be_clickable((By.ID, xpath)))\n",
    "        elif type.lower() == \"css\":\n",
    "            element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, xpath)))\n",
    "        elif type.lower() == \"class\":\n",
    "            element = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, xpath)))\n",
    "        elif type.lower() == \"link\":\n",
    "            element = wait.until(EC.element_to_be_clickable((By.LINK_TEXT, xpath)))\n",
    "        else:\n",
    "            print(f\"Unsupported locator type: {type}\")\n",
    "            return False\n",
    "        \n",
    "        element.click()\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    except (ElementClickInterceptedException, NoSuchElementException, StaleElementReferenceException) as e:\n",
    "        print(f\"Error clicking element: {e}\")\n",
    "        return False\n",
    "    except TimeoutException:\n",
    "        print(f\"Timeout: Element not clickable after {timeout} seconds: {xpath}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected exception: {e}\")\n",
    "        return False\n",
    "    \n",
    "def check_obscures(browser, xpath, type):\n",
    "    \"\"\"\n",
    "    Checks if an element is being obstructed and clicks it if possible.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if type == \"xpath\":\n",
    "            browser.find_element('xpath', xpath).click()\n",
    "        elif type == \"id\":\n",
    "            browser.find_element('id', xpath).click()\n",
    "        elif type == \"css\":\n",
    "            browser.find_element('css selector', xpath).click()\n",
    "        elif type == \"class\":\n",
    "            browser.find_element('class name', xpath).click()\n",
    "        elif type == \"link\":\n",
    "            browser.find_element('link text', xpath).click()\n",
    "    except (ElementClickInterceptedException, NoSuchElementException, StaleElementReferenceException) as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening booking:\n",
    "firefox_binary_path = r\"C:\\Program Files\\Mozilla Firefox\\firefox.exe\"\n",
    "dfolder='./downloads'\n",
    "geko_path = r\"C:\\Users\\aleja\\OneDrive\\Escritorio\\Term_2\\Text_Mining\\geckodriver.exe\"\n",
    "link='https://www.booking.com/index.es.html'\n",
    "browser=start_up(link, dfolder, geko_path, firefox_binary_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated language selection\n",
    "\n",
    "# Language selection\n",
    "browser.find_element(By.XPATH, '//button[@aria-controls=\"header_language_picker\"]').click()\n",
    "# Selecting Spanish\n",
    "browser.find_element(By.XPATH, '//span[@lang=\"es\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cookie rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cookie consent rejected.\n"
     ]
    }
   ],
   "source": [
    "success = check_and_click(browser, \"onetrust-reject-all-handler\", \"id\", timeout=10)\n",
    "\n",
    "if success:\n",
    "    print(\"Cookie consent rejected.\")\n",
    "else:\n",
    "    print(\"Failed to reject cookies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding \"where are you going?\" Button\n",
    "time.sleep(3)  # Wait for 3 seconds before clicking\n",
    "browser.find_element(by=By.XPATH,value='//*[@id=\":rh:\"]').click()\n",
    "\n",
    "# Place input\n",
    "place = 'Lisboa' #switch to Lisboa (spanish for Lisbon)\n",
    "search1 = browser.find_element(by='xpath',value='//*[@id=\":rh:\"]')\n",
    "search1.send_keys(place)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicked the dates box.\n"
     ]
    }
   ],
   "source": [
    "# Clicking the date box\n",
    "\n",
    "locator = '[data-testid=\"searchbox-dates-container\"]'\n",
    "type = \"css\"\n",
    "success = check_and_click(browser, locator, type, timeout=10)\n",
    "if success:\n",
    "    print(\"Clicked the dates box.\")\n",
    "else:\n",
    "    print(\"Failed to click the dates box.\")\n",
    "\n",
    "# Selecting may according to the current month when the code is run\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current month number (1 = January, 2 = February, ..., 12 = December)\n",
    "current_month = datetime.now().month\n",
    "\n",
    "# Calculate the number of clicks needed to reach May (month 5)\n",
    "clicks_needed = max(0, 5 - current_month)\n",
    "\n",
    "# Click the \"Next month\" button the required number of times\n",
    "for _ in range(clicks_needed):\n",
    "    check_and_click(browser, '//button[@class=\"a83ed08757 c21c56c305 f38b6daa18 d691166b09 f671049264 f4552b6561 dc72a8413c f073249358\"]', \"xpath\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecting the dates\n",
    "path='//div[@id=\"calendar-searchboxdatepicker\"]//table[@class=\"eb03f3f27f\"]//tbody//td[@class=\"b80d5adb18\"]//span[@class=\"cf06f772fa ef091eb985\"]'\n",
    "dates = browser.find_elements('xpath',path)\n",
    "\n",
    "arrival = '22-05-2025' #input day of arrival as day , month\n",
    "departure = '26-05-2025' # input day of departure as day, month\n",
    "\n",
    "\n",
    "for date in dates:\n",
    "    if date.get_attribute(\"data-date\") == f\"2025-{arrival.split('-')[1]}-{arrival.split('-')[0]}\":\n",
    "        date.click()\n",
    "    if date.get_attribute(\"data-date\") == f\"2025-{departure.split('-')[1]}-{departure.split('-')[0]}\":\n",
    "        date.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_element(by=By.XPATH,value='//button[@class=\"a83ed08757 c21c56c305 a4c1805887 f671049264 a2abacf76b c082d89982 cceeb8986b b9fd3c6b3c\"]').click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop-up closed.\n"
     ]
    }
   ],
   "source": [
    "# Closing Genius Pop Up (if it appears)\n",
    "try:\n",
    "    success = check_and_click(browser, '//div[@class=\"eb33ef7c47\"]//button[@class=\"a83ed08757 c21c56c305 f38b6daa18 d691166b09 ab98298258 f4552b6561\"]', \"xpath\")\n",
    "    if success:\n",
    "        print(\"Pop-up closed.\")\n",
    "except NoSuchElementException:\n",
    "    print(\"Pop-up did not appear, continuing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout: Element not clickable after 10 seconds: //button[@class=\"a83ed08757 c21c56c305 bf0537ecb5 f671049264 af7297d90d c0e0affd09\"]\n",
      "The 'Load More' button has been clicked 37 times\n"
     ]
    }
   ],
   "source": [
    "# Loading all results\n",
    "\n",
    "clicks = 0\n",
    "# Scrolling based on the height of the page.\n",
    "while True:\n",
    "    try:\n",
    "        total_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        scroll_position = (total_height * 10) - 200 \n",
    "        #we scroll to the bottom of the page, and then back up a bit to reach the desired button\n",
    "        browser.execute_script(f\"window.scrollTo(0, {scroll_position});\")\n",
    "\n",
    "        # Attempt to click the \"Load More\" button using check_and_click.\n",
    "        success = check_and_click(browser, '//button[@class=\"a83ed08757 c21c56c305 bf0537ecb5 f671049264 af7297d90d c0e0affd09\"]', \"xpath\", timeout=10)\n",
    "        \n",
    "        if not success:\n",
    "            break  # Exit loop if button is not found or not clickable.\n",
    "        \n",
    "        clicks += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error while scrolling and clicking: {e}\")\n",
    "        break\n",
    "\n",
    "print(f\"The 'Load More' button has been clicked {clicks} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_source = browser.page_source\n",
    "soup = BeautifulSoup(page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_hotels_metadata(soup):\n",
    "    # We will store each hotel metadata here   \n",
    "    hotel_metadadata = []\n",
    "\n",
    "    # This is our way to find all hotels from the soup\n",
    "    hotels = soup.find_all('div', {'data-testid': 'property-card'})\n",
    "    \n",
    "    for hotel in hotels:\n",
    "        # Extract hotel name\n",
    "        name = hotel.find('div', {'data-testid': 'title'}).get_text(strip=True) if hotel.find('div', {'data-testid': 'title'}) else \"NA\"\n",
    "        \n",
    "        # Extract price\n",
    "        price_unprocessed = hotel.find('span', {'class': 'f6431b446c fbfd7c1165 e84eb96b1f'}).get_text(strip=True) if hotel.find('span', {'class': 'f6431b446c fbfd7c1165 e84eb96b1f'}) else \"NA\"\n",
    "        price = re.sub(r'\\D', '', price_unprocessed)\n",
    "        \n",
    "        # Extract rating\n",
    "        rating_box = hotel.find('div', {'data-testid': 'review-score'})\n",
    "        rating = rating_box.find('div').get_text(strip=True)[-3:].replace(',', '.') if rating_box else \"NA\"\n",
    "\n",
    "        # Extract link to detailed hotel page\n",
    "        hotel_link = hotel.find('a', {'data-testid': 'title-link'})['href'] if hotel.find('a', {'data-testid': 'title-link'}) else None \n",
    "                \n",
    "        hotel_metadadata.append([name, price, rating, hotel_link])\n",
    "    \n",
    "    df = pd.DataFrame(hotel_metadadata, columns=['Name', 'Price', 'Rating', 'Hotel Link'])\n",
    "    return df\n",
    "\n",
    "def scrape_hotel_description(detail_url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(detail_url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        description = soup.find('p', {'data-testid': 'property-description'}).get_text(strip=True) if soup.find('p', {'data-testid': 'property-description'}) else \"NA\"\n",
    "        return description\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping details from {detail_url}: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "def full_program(soup):\n",
    "    # Scrape the listing page using Selenium\n",
    "    metadata = scrape_hotels_metadata(soup)    \n",
    "    \n",
    "    # Scrape each hotel's detailed page for additional information using ThreadPoolExecutor\n",
    "    descriptions = []\n",
    "    with ThreadPoolExecutor(max_workers=16) as executor:  # Adjust the number of workers as needed\n",
    "        future_to_url = {executor.submit(scrape_hotel_description, row['Hotel Link']): index for index, row in metadata.iterrows() if row['Hotel Link']}\n",
    "        \n",
    "        for future in future_to_url:\n",
    "            index = future_to_url[future]\n",
    "            try:\n",
    "                descriptions.append(future.result())\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing hotel at index {index}: {e}\")\n",
    "                descriptions.append(\"Error\")\n",
    "    \n",
    "    # Ensure we maintain order by adding \"NA\" for hotels without links\n",
    "    metadata['Description'] = [descriptions.pop(0) if row['Hotel Link'] else \"NA\" for _, row in metadata.iterrows()]\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    metadata.to_csv(\"hotel_data.csv\", index=False)\n",
    "    print(\"Hotel data saved to hotel_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotel data saved to hotel_data.csv\n"
     ]
    }
   ],
   "source": [
    "df = full_program(soup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
